import streamlit as st
import pandas as pd

from src.automata import EPSILON, build_automata_from_regex, prepare_test_results, trace_dfa, trace_nfa
from src.exporting import get_dot_strings, render_dot_to_png_bytes
from src.html_export import generate_frontend_html


DEFAULT_REGEX = "(a|b)*abb"
DEFAULT_STRINGS = "abb\naabb\nab\n"

def _sanitize_filename(text: str) -> str:
    cleaned = "".join(ch if ch.isalnum() else "_" for ch in text)
    trimmed = cleaned.strip("_")
    return trimmed[:30] or "automaton"


def _collect_states_from_nfa(nfa) -> list[int]:
    states = {nfa.start, nfa.accept}
    for src, mapping in nfa.transitions.items():
        states.add(src)
        for dsts in mapping.values():
            states.update(dsts)
    return sorted(states)


def _collect_states_from_dfa(dfa) -> list[int]:
    states = {dfa.start, *dfa.accepts}
    for src, mapping in dfa.transitions.items():
        states.add(src)
        states.update(mapping.values())
    return sorted(states)


def _nfa_table_df(nfa) -> pd.DataFrame:
    symbols = sorted({sym for m in nfa.transitions.values() for sym in m if sym is not EPSILON})
    has_epsilon = any(EPSILON in m for m in nfa.transitions.values())
    cols = symbols + (["Îµ"] if has_epsilon else [])
    rows = []
    for s in _collect_states_from_nfa(nfa):
        row = {"state": s, "start": (s == nfa.start), "accept": (s == nfa.accept)}
        for sym in symbols:
            dsts = nfa.transitions.get(s, {}).get(sym, set())
            row[sym] = "{" + ",".join(map(str, sorted(dsts))) + "}" if dsts else ""
        if has_epsilon:
            dsts = nfa.transitions.get(s, {}).get(EPSILON, set())
            row["Îµ"] = "{" + ",".join(map(str, sorted(dsts))) + "}" if dsts else ""
        rows.append(row)
    df = pd.DataFrame(rows).set_index("state")
    return df[["start", "accept"] + cols]


def _dfa_table_df(dfa) -> pd.DataFrame:
    symbols = sorted(dfa.alphabet)
    rows = []
    for s in _collect_states_from_dfa(dfa):
        row = {"state": s, "start": (s == dfa.start), "accept": (s in dfa.accepts)}
        for sym in symbols:
            nxt = dfa.transitions.get(s, {}).get(sym)
            row[sym] = "" if nxt is None else str(nxt)
        rows.append(row)
    df = pd.DataFrame(rows).set_index("state")
    return df[["start", "accept"] + symbols]


def main() -> None:
    st.set_page_config(page_title="Lab2-new è‡ªåŠ¨æœºå¯è§†åŒ–", page_icon="ğŸ”", layout="wide")

    st.title("ğŸ” Lab2-newï¼šæ­£åˆ™ â†’ NFA â†’ DFA â†’ æœ€å° DFA")
    st.caption("åç«¯ç®—æ³•åœ¨ `lab2-new/src/`ï¼Œå‰ç«¯ä½¿ç”¨ Streamlit å±•ç¤ºä¸å¯¼å‡ºã€‚")

    with st.sidebar:
        st.header("è¾“å…¥")
        regex = st.text_input("æ­£åˆ™è¡¨è¾¾å¼", value=DEFAULT_REGEX, help="æ”¯æŒï¼šæ‹¬å·()ã€å¹¶|ã€é—­åŒ…*ã€éšå¼è¿æ¥ã€‚")
        st.divider()
        st.header("æ£€æµ‹")
        single = st.text_input("å•ä¸²æ£€æµ‹", value="abb")
        multi = st.text_area("æ‰¹é‡æ£€æµ‹ï¼ˆæ¯è¡Œä¸€ä¸ªï¼‰", value=DEFAULT_STRINGS, height=160)

    if not regex.strip():
        st.info("è¯·è¾“å…¥æ­£åˆ™è¡¨è¾¾å¼ã€‚")
        return

    try:
        nfa, dfa, mdfa = build_automata_from_regex(regex.strip())
    except Exception as exc:
        st.error(f"æ„é€ è‡ªåŠ¨æœºå¤±è´¥ï¼š{exc}")
        return

    meta = {
        "alphabet": sorted(dfa.alphabet),
        "dfa_states": len(dfa.transitions),
        "mdfa_states": len(mdfa.transitions),
    }

    c1, c2, c3 = st.columns(3)
    c1.metric("å­—æ¯è¡¨", ", ".join(meta["alphabet"]) if meta["alphabet"] else "(ç©º)")
    c2.metric("DFA çŠ¶æ€æ•°", meta["dfa_states"])
    c3.metric("æœ€å° DFA çŠ¶æ€æ•°", meta["mdfa_states"])

    tabs = st.tabs(["å›¾å½¢", "è½¬ç§»è¡¨", "æ£€æµ‹ç»“æœ", "å¯¼å‡º"])
    dots = get_dot_strings(nfa, dfa, mdfa)

    with tabs[0]:
        t1, t2, t3 = st.tabs(["NFA", "DFA", "MinDFA"])
        for tab, key, title in [(t1, "nfa", "NFA"), (t2, "dfa", "DFA"), (t3, "mdfa", "MinDFA")]:
            with tab:
                st.subheader(title)
                st.graphviz_chart(dots[key], use_container_width=True)
                with st.expander("DOT æºç ", expanded=False):
                    st.code(dots[key], language="dot")

    with tabs[1]:
        st.subheader("NFA è½¬ç§»è¡¨")
        st.dataframe(_nfa_table_df(nfa), use_container_width=True)
        st.subheader("DFA è½¬ç§»è¡¨")
        st.dataframe(_dfa_table_df(dfa), use_container_width=True)
        st.subheader("æœ€å° DFA è½¬ç§»è¡¨")
        st.dataframe(_dfa_table_df(mdfa), use_container_width=True)

    with tabs[2]:
        st.subheader("å•ä¸²")
        nfa_path, nfa_ok, nfa_reason = trace_nfa(nfa, single)
        dfa_path, dfa_ok, dfa_reason = trace_dfa(dfa, single)
        mdfa_path, mdfa_ok, mdfa_reason = trace_dfa(mdfa, single)
        st.write(f"NFAï¼š`{nfa_ok}`ï¼ŒåŸå› ï¼š{nfa_reason}ï¼›è·¯å¾„ï¼š`{' -> '.join(map(str, nfa_path))}`")
        st.write(f"DFAï¼š`{dfa_ok}`ï¼ŒåŸå› ï¼š{dfa_reason}ï¼›è·¯å¾„ï¼š`{' -> '.join(map(str, dfa_path))}`")
        st.write(f"MinDFAï¼š`{mdfa_ok}`ï¼ŒåŸå› ï¼š{mdfa_reason}ï¼›è·¯å¾„ï¼š`{' -> '.join(map(str, mdfa_path))}`")

        st.divider()
        st.subheader("æ‰¹é‡")
        inputs = [line.strip() for line in multi.splitlines() if line.strip()]
        results = prepare_test_results(nfa, dfa, mdfa, inputs)
        if results:
            df = pd.DataFrame(
                [
                    {
                        "input": r["input"],
                        "NFA": r["nfa_accept"],
                        "DFA": r["dfa_accept"],
                        "MinDFA": r["mdfa_accept"],
                        "MinDFA path": " -> ".join(map(str, r["mdfa_path"])),
                    }
                    for r in results
                ]
            )
            st.dataframe(df, use_container_width=True)
        else:
            st.info("æœªè¾“å…¥æ‰¹é‡å­—ç¬¦ä¸²ã€‚")

    with tabs[3]:
        st.subheader("Graphviz å¯¼å‡º")
        base = f"automaton_{_sanitize_filename(regex)}"
        st.download_button("ä¸‹è½½ NFA dot", data=dots["nfa"], file_name=f"{base}_nfa.dot", mime="text/vnd.graphviz")
        st.download_button("ä¸‹è½½ DFA dot", data=dots["dfa"], file_name=f"{base}_dfa.dot", mime="text/vnd.graphviz")
        st.download_button("ä¸‹è½½ MinDFA dot", data=dots["mdfa"], file_name=f"{base}_mdfa.dot", mime="text/vnd.graphviz")

        png_nfa = render_dot_to_png_bytes(dots["nfa"])
        png_dfa = render_dot_to_png_bytes(dots["dfa"])
        png_mdfa = render_dot_to_png_bytes(dots["mdfa"])
        if png_nfa and png_dfa and png_mdfa:
            st.download_button("ä¸‹è½½ NFA png", data=png_nfa, file_name=f"{base}_nfa.png", mime="image/png")
            st.download_button("ä¸‹è½½ DFA png", data=png_dfa, file_name=f"{base}_dfa.png", mime="image/png")
            st.download_button("ä¸‹è½½ MinDFA png", data=png_mdfa, file_name=f"{base}_mdfa.png", mime="image/png")
        else:
            st.info("æœªæ£€æµ‹åˆ°å¯ç”¨çš„ `dot` æ¸²æŸ“ï¼ˆæˆ–æ¸²æŸ“å¤±è´¥ï¼‰ï¼Œåªèƒ½ä¸‹è½½ dotã€‚")

        st.divider()
        st.subheader("ç¦»çº¿ HTML å¯¼å‡ºï¼ˆlab2 åŠŸèƒ½ç»§æ‰¿ï¼‰")
        batch_inputs = [line.strip() for line in multi.splitlines() if line.strip()]
        results = prepare_test_results(nfa, dfa, mdfa, batch_inputs)
        html = generate_frontend_html(regex=regex.strip(), test_results=results, meta=meta)
        st.download_button("ä¸‹è½½ visualization.html", data=html, file_name="visualization.html", mime="text/html")


if __name__ == "__main__":
    main()
